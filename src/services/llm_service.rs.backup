//! LLM 服务 - 业务能力层
//!
//! 只负责"LLM 判断"能力，不关心流程
//!
//! ## 技术栈
//! - 使用 `openai` crate 进行 API 调用
//! - 支持自定义 API 端点和模型

use anyhow::Result;
use openai::chat::{ChatCompletion, ChatCompletionMessage, ChatCompletionMessageRole};
use openai::Credentials;
use tracing::{debug, warn};

use crate::config::Config;
use crate::models::question::SearchResult;

pub struct LlmService {
    api_key: String,
    api_base_url: String,
    model_name: String,
}

impl LlmService {
    /// 创建新的 LLM 服务
    pub fn new(config: &Config) -> Self {
        Self {
            api_key: config.llm_api_key.clone(),
            api_base_url: config.llm_api_base_url.clone(),
            model_name: config.llm_model_name.clone(),
        }
    }

    pub async fn send_to_llm(
        &self,
        user_message: &str,
        system_message: Option<&str>,
    ) -> Result<String> {
        debug!("调用 LLM API，模型: {}", self.model_name);
        debug!("用户消息长度: {} 字符", user_message.len());

        // 创建凭证
        let credentials = Credentials::new(&self.api_key, &self.api_base_url);

        // 构建消息列表
        let mut messages = Vec::new();

        // 添加系统消息（如果提供）
        if let Some(sys_msg) = system_message {
            messages.push(ChatCompletionMessage {
                role: ChatCompletionMessageRole::System,
                content: Some(sys_msg.to_string()),
                name: None,
                function_call: None,
                tool_call_id: None,
                tool_calls: None,
            });
        }

        // 添加用户消息
        messages.push(ChatCompletionMessage {
            role: ChatCompletionMessageRole::User,
            content: Some(user_message.to_string()),
            name: None,
            function_call: None,
            tool_call_id: None,
            tool_calls: None,
        });

        // 调用 API
        let chat_completion = ChatCompletion::builder(&self.model_name, messages)
            .credentials(credentials)
            .create()
            .await
            .map_err(|e| {
                warn!("LLM API 调用失败: {}", e);
                anyhow::anyhow!("LLM API 调用失败: {}", e)
            })?;

        debug!("LLM API 调用成功");

        // 提取响应内容
        let returned_message = chat_completion
            .choices
            .first()
            .ok_or_else(|| anyhow::anyhow!("LLM 返回结果为空"))?
            .message
            .clone();

        let content = returned_message
            .content
            .ok_or_else(|| anyhow::anyhow!("LLM 返回内容为空"))?;

        Ok(content.trim().to_string())
    }

    /// 从搜索结果中找到最佳匹配
    ///
    /// 这个函数基于 `send_to_llm` 实现，专门用于题目匹配场景。
    ///
    /// # 参数
    /// - `search_results`: 搜索结果列表
    /// - `stem`: 题干内容
    /// - `imgs`: 可选的图片 URL 列表
    ///
    /// # 返回
    /// 返回最佳匹配的索引（0-based）
    ///
    /// # 示例
    /// ```no_run
    /// # use add_question_submit::services::LlmService;
    /// # use add_question_submit::models::question::SearchResult;
    /// # async fn example(service: &LlmService) -> anyhow::Result<()> {
    /// let search_results = vec![/* ... */];
    /// let stem = "1+1等于几？";
    /// let index = service.find_best_match(&search_results, stem, None).await?;
    /// println!("最佳匹配索引: {}", index);
    /// # Ok(())
    /// # }
    /// ```
    pub async fn find_best_match(
        &self,
        search_results: &[SearchResult],
        stem: &str,
        imgs: Option<&[String]>,
    ) -> Result<usize> {
        if search_results.is_empty() {
            anyhow::bail!("搜索结果为空，无法进行匹配");
        }

        debug!(
            "开始 LLM 匹配，候选数量: {}, 模型: {}",
            search_results.len(),
            self.model_name
        );

        // 构建专门用于题目匹配的 prompt
        let (user_message, system_message) = self.build_match_messages(search_results, stem, imgs);

        // 调用通用的 LLM 接口
        let response = self
            .send_to_llm(&user_message, Some(&system_message))
            .await?;

        // 解析响应，提取索引
        let selected_index = self.parse_match_response(&response, search_results.len())?;

        debug!("LLM 选择索引: {} (0-based)", selected_index);

        Ok(selected_index)
    }

    /// 构建用于题目匹配的消息
    ///
    /// 返回 (user_message, system_message)
    fn build_match_messages(
        &self,
        search_results: &[SearchResult],
        stem: &str,
        imgs: Option<&[String]>,
    ) -> (String, String) {
        // 构建系统消息
        let system_message = "你是一个专业的题目匹配助手，擅长通过文字内容和图片信息判断两个题目是否是同一个题目。\
                             你需要综合考虑题目的文字和图片来判断匹配度。\
                             当题目包含图片时，图片URL已包含在提示词中，你需要根据图片信息来判断是否匹配。".to_string();

        // 构建目标题目的图片信息
        let toml_img_info = if let Some(imgs) = imgs {
            if imgs.is_empty() {
                "无图片".to_string()
            } else {
                let img_list: Vec<String> = imgs
                    .iter()
                    .enumerate()
                    .map(|(i, url)| format!("    图片 {}: {}", i + 1, url))
                    .collect();
                format!("包含 {} 张图片：\n{}", imgs.len(), img_list.join("\n"))
            }
        } else {
            "无图片".to_string()
        };

        // 构建候选题目列表（JSON 格式）
        let mut candidates = Vec::new();
        for (idx, result) in search_results.iter().enumerate() {
            let mut candidate = serde_json::json!({
                "index": idx,
                "content": &result.question_content,
                "similarity": result.xkw_question_similarity,
            });

            // 添加图片信息
            if let Some(img_urls) = &result.img_urls {
                candidate["image_count"] = serde_json::json!(img_urls.len());
                candidate["image_urls"] = serde_json::json!(img_urls);
            }

            candidates.push(candidate);
        }

        let candidates_json = serde_json::to_string_pretty(&candidates).unwrap_or_default();

        // 构建候选题目图片信息摘要
        let mut candidate_img_info = String::new();
        for (idx, result) in search_results.iter().enumerate() {
            if let Some(img_urls) = &result.img_urls {
                if !img_urls.is_empty() {
                    candidate_img_info.push_str(&format!(
                        "  候选题目 {}: 包含 {} 张图片\n",
                        idx,
                        img_urls.len()
                    ));
                }
            }
        }
        if candidate_img_info.is_empty() {
            candidate_img_info = "  所有候选题目均无图片\n".to_string();
        }

        // 构建用户消息
        let user_message = format!(
            r#"你需要判断目标题目和候选题目列表中哪个是同一个题目。

【重要说明】
- 目标题目（来自TOML文件）和候选题目（来自题库搜索结果）都可能有图片
- 你需要同时比较题目的文字内容和图片内容
- 判断标准：是否是同一个题目，而不仅仅是相似
- 如果题目包含图片，图片内容也是判断的重要依据
- 两个题目都可能有图片，需要对比图片内容是否相同或相似

目标题目（来自TOML文件）：
  题干内容：{}
  图片信息：{}

候选题目列表（来自题库搜索结果）：
{}

候选题目图片信息：
{}

【判断步骤】
1. 首先比较题目的文字内容是否相同或高度一致
2. 如果目标题目有图片，检查候选题目是否也有相同或相似的图片
3. 如果候选题目有图片，检查目标题目是否也有相同或相似的图片
4. 综合文字内容和图片内容，判断哪个候选题目与目标题目是同一个题目
5. 优先选择文字和图片都匹配的题目

只返回该题目的index数字（0、1、2...），不要返回任何其他内容。"#,
            stem, toml_img_info, candidates_json, candidate_img_info
        );

        (user_message, system_message)
    }

    /// 解析题目匹配的 LLM 响应
    ///
    /// 从 LLM 的响应中提取题目索引
    fn parse_match_response(&self, response: &str, max_index: usize) -> Result<usize> {
        let response = response.trim();

        // 尝试直接解析数字
        if let Ok(index) = response.parse::<usize>() {
            if index < max_index {
                return Ok(index);
            } else {
                warn!(
                    "LLM 返回的索引 {} 超出范围 [0, {}]，使用默认值 0",
                    index,
                    max_index - 1
                );
                return Ok(0);
            }
        }

        // 尝试从文本中提取数字
        for word in response.split_whitespace() {
            let cleaned = word.trim_matches(|c: char| !c.is_numeric());
            if let Ok(index) = cleaned.parse::<usize>() {
                if index < max_index {
                    debug!("从响应 '{}' 中提取到索引: {}", response, index);
                    return Ok(index);
                }
            }
        }

        // 如果无法解析，返回默认值 0
        warn!("无法解析 LLM 响应: '{}', 默认选择第一个候选", response);
        Ok(0)
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    /// 创建测试用的 LlmService
    fn create_test_service() -> LlmService {
        LlmService {
            api_key: std::env::var("LLM_API_KEY").unwrap_or_else(|_| "test_api_key".to_string()),
            api_base_url: std::env::var("LLM_API_BASE_URL")
                .unwrap_or_else(|_| "https://api.openai.com/v1/chat/completions".to_string()),
            model_name: std::env::var("LLM_MODEL_NAME")
                .unwrap_or_else(|_| "gpt-3.5-turbo".to_string()),
        }
    }

    /// 创建测试用的搜索结果
    fn create_test_search_results() -> Vec<SearchResult> {
        vec![
            SearchResult {
                question_content: "北京是中国的首都。".to_string(),
                xkw_question_similarity: Some(0.95),
                img_urls: None,
            },
            SearchResult {
                question_content: "上海是中国的经济中心。".to_string(),
                xkw_question_similarity: Some(0.85),
                img_urls: Some(vec!["https://example.com/img1.jpg".to_string()]),
            },
            SearchResult {
                question_content: "广州是广东省的省会。".to_string(),
                xkw_question_similarity: Some(0.75),
                img_urls: Some(vec![
                    "https://example.com/img2.jpg".to_string(),
                    "https://example.com/img3.jpg".to_string(),
                ]),
            },
        ]
    }

    #[test]
    fn test_build_messages_basic() {
        let service = create_test_service();
        let search_results = create_test_search_results();
        let stem = "中国的首都是哪里？";

        let (user_message, system_message) =
            service.build_match_messages(&search_results, stem, None);

        // 验证系统消息
        assert!(system_message.contains("题目匹配助手"));
        assert!(system_message.contains("文字内容和图片"));

        // 验证用户消息包含关键信息
        assert!(user_message.contains("目标题目"));
        assert!(user_message.contains(stem));
        assert!(user_message.contains("候选题目列表"));
        assert!(user_message.contains("北京是中国的首都"));
        assert!(user_message.contains("只返回该题目的index数字"));
    }

    #[test]
    fn test_build_messages_with_images() {
        let service = create_test_service();
        let search_results = create_test_search_results();
        let stem = "测试题目";
        let imgs = vec![
            "https://example.com/q1.jpg".to_string(),
            "https://example.com/q2.jpg".to_string(),
        ];

        let (user_message, _) = service.build_match_messages(&search_results, stem, Some(&imgs));

        // 验证包含目标题目的图片信息
        assert!(user_message.contains("包含 2 张图片"));
        assert!(user_message.contains("图片 1: https://example.com/q1.jpg"));
        assert!(user_message.contains("图片 2: https://example.com/q2.jpg"));

        // 验证包含候选题目的图片信息
        assert!(user_message.contains("候选题目 1: 包含 1 张图片"));
        assert!(user_message.contains("候选题目 2: 包含 2 张图片"));
    }

    #[test]
    fn test_parse_llm_response_direct_number() {
        let service = create_test_service();

        // 测试直接返回数字
        assert_eq!(service.parse_match_response("0", 3).unwrap(), 0);
        assert_eq!(service.parse_match_response("1", 3).unwrap(), 1);
        assert_eq!(service.parse_match_response("2", 3).unwrap(), 2);
    }

    #[test]
    fn test_parse_llm_response_with_whitespace() {
        let service = create_test_service();

        // 测试带空格的响应
        assert_eq!(service.parse_match_response(" 0 ", 3).unwrap(), 0);
        assert_eq!(service.parse_match_response("  1  ", 3).unwrap(), 1);
        assert_eq!(service.parse_match_response("\n2\n", 3).unwrap(), 2);
    }

    #[test]
    fn test_parse_llm_response_with_text() {
        let service = create_test_service();

        // 测试包含文字的响应
        assert_eq!(service.parse_match_response("我选择 0", 3).unwrap(), 0);
        assert_eq!(service.parse_match_response("答案是 1", 3).unwrap(), 1);
        assert_eq!(service.parse_match_response("2 是最匹配的", 3).unwrap(), 2);
    }

    #[test]
    fn test_parse_llm_response_out_of_range() {
        let service = create_test_service();

        // 测试超出范围的数字，应返回默认值 0
        assert_eq!(service.parse_match_response("999", 3).unwrap(), 0);
        assert_eq!(service.parse_match_response("100", 3).unwrap(), 0);
    }

    #[test]
    fn test_parse_llm_response_invalid() {
        let service = create_test_service();

        // 测试无法解析的响应，应返回默认值 0
        assert_eq!(service.parse_match_response("无法判断", 3).unwrap(), 0);
        assert_eq!(service.parse_match_response("I don't know", 3).unwrap(), 0);
    }

    #[test]
    fn test_find_best_match_empty_results() {
        let service = create_test_service();
        let empty_results: Vec<SearchResult> = vec![];

        let result = tokio_test::block_on(service.find_best_match(&empty_results, "测试", None));

        // 应该返回错误
        assert!(result.is_err());
        assert!(result.unwrap_err().to_string().contains("搜索结果为空"));
    }

    #[test]
    fn test_parse_various_formats() {
        let service = create_test_service();

        let test_cases = vec![
            ("0", 0),
            ("1", 1),
            ("2", 2),
            ("答案是0", 0),
            ("I choose 1", 1),
            ("第2个", 2),
            ("0.", 0),
            ("(1)", 1),
            ("[2]", 2),
        ];

        for (response, expected) in test_cases {
            let result = service.parse_match_response(response, 5).unwrap();
            assert_eq!(
                result, expected,
                "解析 '{}' 失败，期望 {}，实际 {}",
                response, expected, result
            );
        }
    }

    /// 测试 LLM API 连接性
    ///
    /// 注意：此测试需要网络连接
    ///
    /// 运行方式：
    /// ```bash
    /// cargo test test_llm_api_connectivity -- --ignored --nocapture
    /// ```
    #[tokio::test]
    #[ignore] // 默认忽略，需要手动运行
    async fn test_llm_api_connectivity() {
        // 初始化日志
        let _ = tracing_subscriber::fmt::try_init();

        // 使用默认配置
        let service = LlmService {
            api_key: "26e96c4d312e48feacbd78b7c42bd71e".to_string(),
            api_base_url: "http://menshen.xdf.cn/v1".to_string(),
            model_name: "doubao-seed-1.6".to_string(),
        };

        // 创建简单的测试数据
        let search_results = vec![
            SearchResult {
                question_content: "北京是中国的首都。".to_string(),
                xkw_question_similarity: Some(0.95),
                img_urls: Some(vec![String::from("https://img.xkw.com/dksih/QBM/editorImg/2025/12/26/3be3aad4-f19c-46b0-9682-b34a72a56014.png?resizew=93")]),
            },
            SearchResult {
                question_content: "上海是中国的经济中心。".to_string(),
                xkw_question_similarity: Some(0.85),
                img_urls: None,
            },
        ];

        let stem = "中国的首都是哪里？";

        // 测试 API 调用
        let result = service.find_best_match(&search_results, stem, None).await;

        match result {
            Ok(index) => {
                println!("✅ LLM API 调用成功！");
                println!("选择的索引: {}", index);
                println!("选择的内容: {}", search_results[index].question_content);
                assert!(index < search_results.len());
            }
            Err(e) => {
                println!("❌ LLM API 调用失败: {}", e);
                panic!("LLM API 测试失败: {}", e);
            }
        }
    }

    /// 测试消息构建的完整性
    #[test]
    fn test_message_structure() {
        let service = create_test_service();
        let search_results = create_test_search_results();
        let stem = "测试题目";
        let imgs = vec!["https://example.com/img.jpg".to_string()];

        let (user_message, system_message) =
            service.build_match_messages(&search_results, stem, Some(&imgs));

        // 验证系统消息结构
        assert!(!system_message.is_empty());
        assert!(system_message.len() > 50);

        // 验证用户消息结构
        assert!(user_message.contains("【重要说明】"));
        assert!(user_message.contains("【判断步骤】"));
        assert!(user_message.contains("目标题目"));
        assert!(user_message.contains("候选题目列表"));
        assert!(user_message.contains("只返回该题目的index数字"));
    }

    /// 测试通用的 send_to_llm 函数
    #[test]
    fn test_send_to_llm_message_structure() {
        // 测试消息构建逻辑
        let _service = create_test_service();

        // 这里只测试消息构建，不实际调用 API
        // 验证 send_to_llm 可以接受各种输入

        let user_msg = "简单的问题";
        let system_msg = Some("你是一个助手");

        // 验证参数接受正确
        assert!(!user_msg.is_empty());
        assert!(system_msg.is_some());
    }

    /// 测试通用 LLM 调用（简单问答）
    ///
    /// 运行方式：
    /// ```bash
    /// cargo test test_send_to_llm_simple -- --ignored --nocapture
    /// ```
    #[tokio::test]
    #[ignore]
    async fn test_send_to_llm_simple() {
        // 初始化日志
        let _ = tracing_subscriber::fmt::try_init();

        let service = LlmService {
            api_key: "26e96c4d312e48feacbd78b7c42bd71e".to_string(),
            api_base_url: "http://menshen.xdf.cn/v1".to_string(),
            model_name: "doubao-seed-1.6".to_string(),
        };

        println!("\n========== 测试通用 LLM 调用 ==========");

        let user_message = "请用一句话介绍北京。";
        let system_message = Some("你是一个简洁的助手，回答要简短。");

        println!("用户消息: {}", user_message);
        println!("系统消息: {:?}", system_message);
        println!("=====================================\n");

        let result = service.send_to_llm(user_message, system_message).await;

        match result {
            Ok(response) => {
                println!("\n========== LLM 响应 ==========");
                println!("{}", response);
                println!("==============================\n");
                println!("✅ 通用 LLM 调用成功！");
                assert!(!response.is_empty());
            }
            Err(e) => {
                println!("❌ 通用 LLM 调用失败: {}", e);
                panic!("测试失败: {}", e);
            }
        }
    }

    /// 测试 send_to_llm 不带系统消息
    #[tokio::test]
    #[ignore]
    async fn test_send_to_llm_without_system() {
        let _ = tracing_subscriber::fmt::try_init();

        let service = LlmService {
            api_key: "26e96c4d312e48feacbd78b7c42bd71e".to_string(),
            api_base_url: "http://menshen.xdf.cn/v1".to_string(),
            model_name: "doubao-seed-1.6".to_string(),
        };

        println!("\n========== 测试无系统消息的 LLM 调用 ==========");

        let user_message = "1+1等于几？只回答数字。";
        println!("用户消息: {}", user_message);
        println!("系统消息: None");
        println!("==========================================\n");

        let result = service.send_to_llm(user_message, None).await;

        match result {
            Ok(response) => {
                println!("\n========== LLM 响应 ==========");
                println!("{}", response);
                println!("==============================\n");
                println!("✅ 无系统消息调用成功！");

                // 验证响应包含数字
                assert!(!response.is_empty());
                assert!(response.contains("2") || response.contains("二"));
            }
            Err(e) => {
                println!("❌ LLM 调用失败: {}", e);
                panic!("测试失败: {}", e);
            }
        }
    }
}
